nextflow.enable.dsl = 2

// define default parameters
params {
    outdir                = './results'
    tracedir              = "${params.outdir}/pipeline_info"
    custom_config_version = 'master'
    custom_config_base    = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
}

// include institute-specific configs from nf-core
try {
    includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch ( Exception e ) {
    System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

// include config for the local profile
profiles {
    local {
        includeConfig 'conf/local.config'
    }
}

// define resource requirements and the container path
process {
    container     = 'oras://docker.io/gerlichlab/peakflow-apptainer:latest'
    conda         = './conda.yml'
    errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
    maxRetries    = 1
    withLabel: 'quick' {
        cpus   = { check_max( 1,                    'cpus'   ) }
        memory = { check_max( 1.GB,                 'memory' ) }
        time   = { check_max( 1.h * task.attempt,   'time'   ) }
    }
    withLabel: 'peaks' {
        cpus   = { check_max( 1,                    'cpus'   ) }
        memory = { check_max( 10.GB * task.attempt, 'memory' ) }
        time   = { check_max( 1.h   * task.attempt, 'time'   ) }
    }
    withLabel: 'tracks' {
        cpus   = { check_max( 8,                    'cpus'   ) }
        memory = { check_max( 10.GB * task.attempt, 'memory' ) }
        time   = { check_max( 1.h   * task.attempt, 'time'   ) }
    }
}

// enable tracing and reporting
def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.html"
}

// Pipeline manifest
manifest {
    author          = 'Dmitry Mylarshchikov'
    description     = 'Peakflow is a simple pipeline for calling peaks and producing tracks with read extension from ChIP-seq data'
    homePage        = 'github.com/dmitrymyl/peakflow'
    name            = 'peakflow'
    nextflowVersion = '>=23.10, <25.06'
    mainScript      = 'main.nf'
    defaultBranch   = 'main'
}

/* 
   Function to ensure that resource requirements don't go beyond a maximum limit.
   Taken from https://github.com/nf-core/chipseq/blob/2.0.0/nextflow.config
*/
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}